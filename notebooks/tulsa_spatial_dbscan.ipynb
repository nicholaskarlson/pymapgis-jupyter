{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🏙️ Tulsa, Oklahoma Spatial DBSCAN Analysis\n",
    "\n",
    "This notebook demonstrates spatial clustering analysis for Tulsa, Oklahoma using PyMapGIS and DBSCAN clustering.\n",
    "\n",
    "## 🎯 Objectives\n",
    "- Generate realistic spatial data for Tulsa hotspots\n",
    "- Apply DBSCAN clustering to identify spatial patterns\n",
    "- Create interactive maps with cluster visualization\n",
    "- Export results for further analysis\n",
    "\n",
    "## 📍 Tulsa Key Locations\n",
    "- **Downtown Tulsa**: Business and entertainment district\n",
    "- **Tulsa International Airport**: Major transportation hub\n",
    "- **University of Tulsa**: Educational institution\n",
    "- **Gathering Place**: Major riverfront park and attraction\n",
    "- **Brookside District**: Shopping and dining area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(\"🗺️ Ready to analyze Tulsa, Oklahoma!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tulsa Configuration\n",
    "CITY_NAME = \"Tulsa\"\n",
    "STATE = \"Oklahoma\"\n",
    "CITY_CENTER = [36.1540, -95.9928]  # Downtown Tulsa coordinates\n",
    "ZOOM_LEVEL = 11\n",
    "\n",
    "# Define Tulsa hotspots (key activity areas)\n",
    "tulsa_hotspots = {\n",
    "    \"Downtown Tulsa\": [36.1540, -95.9928],\n",
    "    \"Tulsa Airport\": [36.1984, -95.8881],\n",
    "    \"University of Tulsa\": [36.1512, -95.9443],\n",
    "    \"Gathering Place\": [36.1615, -95.9880],\n",
    "    \"Brookside District\": [36.1180, -95.9792]\n",
    "}\n",
    "\n",
    "# Geographic boundaries for Tulsa area\n",
    "LAT_MIN, LAT_MAX = 36.05, 36.25\n",
    "LON_MIN, LON_MAX = -96.10, -95.85\n",
    "\n",
    "print(f\"🏙️ Analyzing {CITY_NAME}, {STATE}\")\n",
    "print(f\"📍 City center: {CITY_CENTER}\")\n",
    "print(f\"🎯 Number of hotspots: {len(tulsa_hotspots)}\")\n",
    "print(f\"📏 Analysis area: {LAT_MAX-LAT_MIN:.2f}° × {LON_MAX-LON_MIN:.2f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic spatial data for Tulsa\n",
    "def generate_tulsa_data():\n",
    "    \"\"\"\n",
    "    Generate realistic spatial data points around Tulsa hotspots\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "    \n",
    "    # Points per hotspot (adjust based on area importance)\n",
    "    points_config = {\n",
    "        \"Downtown Tulsa\": 150,      # Major business district\n",
    "        \"Tulsa Airport\": 80,        # Transportation hub\n",
    "        \"University of Tulsa\": 100, # Educational institution\n",
    "        \"Gathering Place\": 120,     # Major attraction\n",
    "        \"Brookside District\": 70    # Shopping/dining area\n",
    "    }\n",
    "    \n",
    "    for hotspot_name, center_coords in tulsa_hotspots.items():\n",
    "        num_points = points_config[hotspot_name]\n",
    "        \n",
    "        # Generate points around each hotspot with realistic spread\n",
    "        lat_center, lon_center = center_coords\n",
    "        \n",
    "        # Adjust spread based on area type\n",
    "        if \"Downtown\" in hotspot_name:\n",
    "            spread = 0.008  # Tight cluster for downtown\n",
    "        elif \"Airport\" in hotspot_name:\n",
    "            spread = 0.012  # Medium spread for airport area\n",
    "        else:\n",
    "            spread = 0.010  # Standard spread for other areas\n",
    "        \n",
    "        # Generate points with normal distribution around center\n",
    "        lats = np.random.normal(lat_center, spread, num_points)\n",
    "        lons = np.random.normal(lon_center, spread, num_points)\n",
    "        \n",
    "        # Ensure points stay within Tulsa boundaries\n",
    "        lats = np.clip(lats, LAT_MIN, LAT_MAX)\n",
    "        lons = np.clip(lons, LON_MIN, LON_MAX)\n",
    "        \n",
    "        # Create point data\n",
    "        for lat, lon in zip(lats, lons):\n",
    "            all_points.append({\n",
    "                'latitude': lat,\n",
    "                'longitude': lon,\n",
    "                'hotspot_origin': hotspot_name,\n",
    "                'point_id': len(all_points)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(all_points)\n",
    "\n",
    "# Generate the data\n",
    "tulsa_data = generate_tulsa_data()\n",
    "\n",
    "print(f\"📊 Generated {len(tulsa_data)} data points for Tulsa analysis\")\n",
    "print(f\"🎯 Hotspot distribution:\")\n",
    "print(tulsa_data['hotspot_origin'].value_counts())\n",
    "print(f\"\\n📍 Coordinate ranges:\")\n",
    "print(f\"   Latitude: {tulsa_data['latitude'].min():.4f} to {tulsa_data['latitude'].max():.4f}\")\n",
    "print(f\"   Longitude: {tulsa_data['longitude'].min():.4f} to {tulsa_data['longitude'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN clustering\n",
    "def apply_spatial_clustering(data, eps_meters=500, min_samples=3):\n",
    "    \"\"\"\n",
    "    Apply DBSCAN clustering to spatial data\n",
    "    \n",
    "    Parameters:\n",
    "    - eps_meters: Maximum distance between points in a cluster (meters)\n",
    "    - min_samples: Minimum number of points required to form a cluster\n",
    "    \"\"\"\n",
    "    # Convert coordinates to a format suitable for clustering\n",
    "    coordinates = data[['latitude', 'longitude']].values\n",
    "    \n",
    "    # Convert eps from meters to degrees (approximate)\n",
    "    # 1 degree ≈ 111,000 meters at the equator\n",
    "    # Adjust for Tulsa's latitude (36.15°)\n",
    "    lat_correction = np.cos(np.radians(36.15))\n",
    "    eps_degrees = eps_meters / (111000 * lat_correction)\n",
    "    \n",
    "    # Apply DBSCAN clustering\n",
    "    dbscan = DBSCAN(eps=eps_degrees, min_samples=min_samples)\n",
    "    cluster_labels = dbscan.fit_predict(coordinates)\n",
    "    \n",
    "    # Add cluster labels to data\n",
    "    data_clustered = data.copy()\n",
    "    data_clustered['cluster'] = cluster_labels\n",
    "    \n",
    "    # Calculate cluster statistics\n",
    "    n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "    n_noise = list(cluster_labels).count(-1)\n",
    "    \n",
    "    print(f\"🔍 DBSCAN Clustering Results:\")\n",
    "    print(f\"   Parameters: eps={eps_meters}m, min_samples={min_samples}\")\n",
    "    print(f\"   Number of clusters: {n_clusters}\")\n",
    "    print(f\"   Number of noise points: {n_noise}\")\n",
    "    print(f\"   Percentage clustered: {((len(data) - n_noise) / len(data) * 100):.1f}%\")\n",
    "    \n",
    "    return data_clustered, n_clusters, n_noise\n",
    "\n",
    "# Apply clustering with Tulsa-appropriate parameters\n",
    "tulsa_clustered, num_clusters, num_noise = apply_spatial_clustering(\n",
    "    tulsa_data, \n",
    "    eps_meters=500,  # 500 meter radius for urban clustering\n",
    "    min_samples=3    # Minimum 3 points per cluster\n",
    ")\n",
    "\n",
    "# Display cluster summary\n",
    "cluster_summary = tulsa_clustered.groupby('cluster').agg({\n",
    "    'latitude': ['count', 'mean'],\n",
    "    'longitude': 'mean',\n",
    "    'hotspot_origin': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Mixed'\n",
    "}).round(4)\n",
    "\n",
    "cluster_summary.columns = ['Point_Count', 'Avg_Latitude', 'Avg_Longitude', 'Primary_Hotspot']\n",
    "print(f\"\\n📈 Cluster Summary:\")\n",
    "print(cluster_summary.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive map visualization\n",
    "def create_tulsa_map(data_clustered):\n",
    "    \"\"\"\n",
    "    Create an interactive Folium map showing Tulsa clusters\n",
    "    \"\"\"\n",
    "    # Create base map centered on Tulsa\n",
    "    tulsa_map = folium.Map(\n",
    "        location=CITY_CENTER,\n",
    "        zoom_start=ZOOM_LEVEL,\n",
    "        tiles='OpenStreetMap'\n",
    "    )\n",
    "    \n",
    "    # Define colors for clusters\n",
    "    cluster_colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkred', \n",
    "                     'lightred', 'beige', 'darkblue', 'darkgreen', 'cadetblue',\n",
    "                     'darkpurple', 'white', 'pink', 'lightblue', 'lightgreen']\n",
    "    \n",
    "    # Add cluster points to map\n",
    "    for idx, row in data_clustered.iterrows():\n",
    "        cluster_id = row['cluster']\n",
    "        \n",
    "        if cluster_id == -1:\n",
    "            # Noise points in gray\n",
    "            color = 'gray'\n",
    "            popup_text = f\"Noise Point\\nOrigin: {row['hotspot_origin']}\"\n",
    "        else:\n",
    "            # Cluster points in assigned colors\n",
    "            color = cluster_colors[cluster_id % len(cluster_colors)]\n",
    "            popup_text = f\"Cluster {cluster_id}\\nOrigin: {row['hotspot_origin']}\"\n",
    "        \n",
    "        folium.CircleMarker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            radius=4,\n",
    "            popup=popup_text,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fillColor=color,\n",
    "            fillOpacity=0.7\n",
    "        ).add_to(tulsa_map)\n",
    "    \n",
    "    # Add hotspot markers\n",
    "    for hotspot_name, coords in tulsa_hotspots.items():\n",
    "        folium.Marker(\n",
    "            location=coords,\n",
    "            popup=f\"📍 {hotspot_name}\",\n",
    "            icon=folium.Icon(color='black', icon='star')\n",
    "        ).add_to(tulsa_map)\n",
    "    \n",
    "    # Add title\n",
    "    title_html = f'''\n",
    "                 <h3 align=\"center\" style=\"font-size:20px\"><b>Tulsa, Oklahoma - Spatial DBSCAN Analysis</b></h3>\n",
    "                 <p align=\"center\">Clusters: {num_clusters} | Points: {len(data_clustered)} | Noise: {num_noise}</p>\n",
    "                 '''\n",
    "    tulsa_map.get_root().html.add_child(folium.Element(title_html))\n",
    "    \n",
    "    return tulsa_map\n",
    "\n",
    "# Create and display the map\n",
    "tulsa_map = create_tulsa_map(tulsa_clustered)\n",
    "print(\"🗺️ Interactive map created successfully!\")\n",
    "print(\"📍 Black stars show original hotspot locations\")\n",
    "print(\"🔴 Colored circles show clustered data points\")\n",
    "print(\"⚫ Gray circles show noise points (not in any cluster)\")\n",
    "\n",
    "# Display the map\n",
    "tulsa_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results for further analysis\n",
    "def export_tulsa_results(data_clustered):\n",
    "    \"\"\"\n",
    "    Export clustering results to CSV and GeoJSON formats\n",
    "    \"\"\"\n",
    "    # Export to CSV\n",
    "    csv_filename = 'tulsa_spatial_analysis.csv'\n",
    "    data_clustered.to_csv(csv_filename, index=False)\n",
    "    print(f\"📄 Results exported to {csv_filename}\")\n",
    "    \n",
    "    # Create GeoDataFrame for spatial export\n",
    "    from shapely.geometry import Point\n",
    "    \n",
    "    geometry = [Point(lon, lat) for lat, lon in zip(data_clustered['latitude'], data_clustered['longitude'])]\n",
    "    gdf = gpd.GeoDataFrame(data_clustered, geometry=geometry, crs='EPSG:4326')\n",
    "    \n",
    "    # Export to GeoJSON\n",
    "    geojson_filename = 'tulsa_clusters.geojson'\n",
    "    gdf.to_file(geojson_filename, driver='GeoJSON')\n",
    "    print(f\"🗺️ Spatial data exported to {geojson_filename}\")\n",
    "    \n",
    "    return csv_filename, geojson_filename\n",
    "\n",
    "# Export the results\n",
    "csv_file, geojson_file = export_tulsa_results(tulsa_clustered)\n",
    "\n",
    "# Generate summary report\n",
    "print(f\"\\n📊 TULSA SPATIAL ANALYSIS SUMMARY\")\n",
    "print(f\"=\"*50)\n",
    "print(f\"City: {CITY_NAME}, {STATE}\")\n",
    "print(f\"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(f\"Total Data Points: {len(tulsa_clustered)}\")\n",
    "print(f\"Number of Clusters: {num_clusters}\")\n",
    "print(f\"Noise Points: {num_noise} ({(num_noise/len(tulsa_clustered)*100):.1f}%)\")\n",
    "print(f\"Clustering Success Rate: {((len(tulsa_clustered)-num_noise)/len(tulsa_clustered)*100):.1f}%\")\n",
    "print(f\"\\n📁 Output Files:\")\n",
    "print(f\"   • {csv_file} - Tabular data with cluster assignments\")\n",
    "print(f\"   • {geojson_file} - Spatial data for GIS applications\")\n",
    "print(f\"\\n🎯 Largest Clusters:\")\n",
    "largest_clusters = tulsa_clustered[tulsa_clustered['cluster'] != -1]['cluster'].value_counts().head(5)\n",
    "for cluster_id, count in largest_clusters.items():\n",
    "    primary_hotspot = tulsa_clustered[tulsa_clustered['cluster'] == cluster_id]['hotspot_origin'].mode().iloc[0]\n",
    "    print(f\"   • Cluster {cluster_id}: {count} points (primarily {primary_hotspot})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Analysis Complete!\n",
    "\n",
    "You've successfully completed a spatial DBSCAN analysis for Tulsa, Oklahoma! \n",
    "\n",
    "### 🔍 What We Discovered\n",
    "- Identified spatial clusters around key Tulsa locations\n",
    "- Analyzed clustering patterns in the city\n",
    "- Created interactive visualizations\n",
    "- Exported results for further analysis\n",
    "\n",
    "### 🚀 Next Steps\n",
    "1. **Experiment with parameters** - Try different `eps` and `min_samples` values\n",
    "2. **Add real data** - Incorporate actual Tulsa datasets (crime, business locations, etc.)\n",
    "3. **Compare with other cities** - Run similar analysis for other Oklahoma cities\n",
    "4. **Temporal analysis** - Add time-based clustering analysis\n",
    "\n",
    "### 🏙️ Create Your Own City Analysis\n",
    "Want to analyze your own city? Check out the **[Add Your City Guide](../ADD_YOUR_CITY_GUIDE.md)** for step-by-step instructions!\n",
    "\n",
    "### 📚 Learn More\n",
    "- **[PyMapGIS on PyPI](https://pypi.org/project/pymapgis/)** - Explore more spatial analysis capabilities\n",
    "- **[DBSCAN Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)** - Learn about clustering parameters\n",
    "- **[Folium Documentation](https://python-visualization.github.io/folium/)** - Create more advanced maps\n",
    "\n",
    "---\n",
    "**Happy spatial analyzing! 🗺️✨**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
